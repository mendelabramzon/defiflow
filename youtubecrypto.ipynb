{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pyyoutube import Api\n",
    "import json\n",
    "import openai\n",
    "from binance.client import Client\n",
    "from binance_historical_data import BinanceDataDumper\n",
    "import googleapiclient.discovery\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio\n",
    "from pytube import YouTube\n",
    "from pytube import Channel\n",
    "import html_to_json\n",
    "import yt_dlp\n",
    "import os\n",
    "import whisper\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load creditionals (youtube, openai, binance) from json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api keys\n",
    "with open('credsyt.json') as f:\n",
    "    yt = json.load(f)[\"apiyt\"]\n",
    "with open('credsyt.json') as f:\n",
    "    ai = json.load(f)[\"apiopenai\"]\n",
    "with open('credsyt.json') as f:\n",
    "    keybin = json.load(f)[\"keybin\"]\n",
    "with open('credsyt.json') as f:\n",
    "    secbin = json.load(f)[\"secretbin\"]\n",
    "with open('credsyt.json') as f:\n",
    "    cmc = json.load(f)[\"apicmc\"]\n",
    "with open('credsyt.json') as f:\n",
    "    cmc_pro = json.load(f)[\"cmc_pro_key\"]\n",
    "with open('all_coins.json') as f:\n",
    "    all_coins = json.load(f)\n",
    "with open('all_binance_tickers.json') as f:\n",
    "    all_bianance_tickers=json.load(f)\n",
    "with open('cmcap_names_1to200mln_cap.json') as f:\n",
    "    cmcap_coins = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish api clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API information\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "# API key\n",
    "DEVELOPER_KEY = yt\n",
    "CMC_PRO_KEY = cmc_pro\n",
    "# API client\n",
    "ytapi = Api(api_key=yt)\n",
    "yapi = Api(access_token='AIzaSyBL8jHle7vrCaMPz27Nc0t-VYBDtddFqfA')\n",
    "aiapi = openai.api_key = ai\n",
    "client = Client(keybin, secbin)\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey = DEVELOPER_KEY)\n",
    "model = whisper.load_model(\"base.en\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sybtitles from video id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_video(video_id):\n",
    "    srt = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    all_keys = [d[\"text\"] for d in srt]\n",
    "    s = ''.join(all_keys)\n",
    "    return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get videos from the playlist, construct json with the followong from \n",
    "## [video_id, video_date, string with text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_playlist(playlist_link):\n",
    "\n",
    "    #CHANNEL_ID = 'https://www.youtube.com/@CoinBureau'\n",
    "    #PLAYLIST_ID = 'UU' + CHANNEL_ID[2:]\n",
    "    PLAYLIST_ID=playlist_link\n",
    "    #PLAYLIST_ID  = \"PLk1ALX7IOH_kC7XYX_BSzJYOkLaRpnqQj\"\n",
    "\n",
    "    URL = f'https://www.googleapis.com/youtube/v3/playlistItems?part=snippet&playlistId={PLAYLIST_ID}&maxResults=100&key={DEVELOPER_KEY}'\n",
    "\n",
    "    pageToken = ''\n",
    "    responses = []\n",
    "    videos_info={}\n",
    "    videos_info.setdefault('date', [])\n",
    "    videos_info.setdefault('id', [])\n",
    "    videos_info.setdefault('text', [])\n",
    "    valid=False\n",
    "    while not valid:\n",
    "        try:\n",
    "            pageUrl = URL\n",
    "            if pageToken != '':\n",
    "                pageUrl += f'&pageToken={pageToken}'\n",
    "            response = json.loads(requests.get(pageUrl).text)\n",
    "            for video in response[\"items\"]:\n",
    "                video_date = video[\"snippet\"][\"publishedAt\"]\n",
    "                video_id = video[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
    "                text = get_text_from_video(video_id=video_id)\n",
    "                videos_info[\"date\"].append(video_date)\n",
    "                videos_info[\"id\"].append(video_id)\n",
    "                videos_info[\"text\"].append(text) \n",
    "            responses.append(response)\n",
    "            if 'nextPageToken' in response:\n",
    "                pageToken = response['nextPageToken']\n",
    "            else: valid = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if 'nextPageToken' in response:\n",
    "                pageToken = response['nextPageToken']\n",
    "            else: valid = True\n",
    "    return videos_info\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which take for input date of the video and subtitles and give as an output a dictionary with the following form: {\"ticker\":[klines]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_klines(date,text):\n",
    "  # using openai get the string of the names of the tokens\n",
    "  response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt='write down a list without spaces of names of cryptocurrency tokens which are mentioned in a positive context in the following text: \\n\\n'+text,\n",
    "  temperature=0.2,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "# transform the string of the names to the list of the symbols\n",
    "  klines_dict=[]\n",
    "  shilling_list = response[\"choices\"][0]['text'][2:].split(',')\n",
    "  print(shilling_list)\n",
    "  counter = 0 \n",
    "  shitcoins=[]\n",
    "  dd = int(datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\").timestamp()*1000)\n",
    "  \n",
    "  for shitcoin in shilling_list:\n",
    "    cntr2 = 0\n",
    "    for cmcoin in all_coins[\"name\"]:\n",
    "      if shitcoin in cmcoin or cmcoin in shitcoin:\n",
    "        shitcoins.append(all_coins[\"symbol\"][counter])\n",
    "        print(shitcoin,cmcoin)\n",
    "      cntr2+=1\n",
    "    counter+=1\n",
    "# for each suitable symbol make a binance ticker of the form *SYMBOL*USDT \n",
    "  \n",
    "  for symbol in shitcoins:\n",
    "    valid=False\n",
    "    while not valid:\n",
    "      try:\n",
    "        print(symbol)\n",
    "        coin_dict={}\n",
    "        ticker=symbol+'USDT'\n",
    "        coin_dict.setdefault(f''+ticker, [])\n",
    "        klines = client.get_historical_klines(symbol=ticker, interval=\"1h\", start_str=dd, end_str=dd+3600*24*1000, limit=1000)\n",
    "        coin_dict[f''+ticker].append(klines)\n",
    "        klines_dict.append(coin_dict)\n",
    "        valid=True\n",
    "      except Exception as e: valid=True\n",
    "  return(klines_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which take by the input a link to the youtube channel, checks if the new video has been uploaded and gives as an output the link to the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_video_info(channel_id):\n",
    "    CHANNEL_ID  = channel_id\n",
    "    url2 = f'https://youtube.googleapis.com/youtube/v3/search?channelId={CHANNEL_ID}&part=snippet&maxResults=10&order=date&type=video&key={DEVELOPER_KEY}'\n",
    "    r = requests.get(url2)\n",
    "    json_output = json.loads(r.text)\n",
    "    list_of_videos = json_output['items']\n",
    "    last_video_date = list_of_videos[0]['snippet']['publishedAt']\n",
    "    last_video_id = list_of_videos[0]['id']['videoId']\n",
    "    return last_video_date,last_video_id\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which takes as an input the link to the youtube video, downloads the audiotrack and finally returns the transcribed text using the whisper openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_and_text(link):\n",
    "    with yt_dlp.YoutubeDL({'extract_audio': True, 'format': 'bestaudio', 'outtmpl': '%(title)s.mp3'}) as video:\n",
    "        info_dict = video.extract_info(link, download = True)\n",
    "        video_title = info_dict['title']\n",
    "        print(video_title)\n",
    "        video.download(link)    \n",
    "        print(\"Successfully Downloaded\")\n",
    "        result = model.transcribe(f'{video_title}.mp3')\n",
    "        text = result[\"text\"]\n",
    "    return text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which takes as an input the text and returns the list of crypto projects mentioned in a positive context using davinci openai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coins_from_text(text):\n",
    "# using openai get the string of the names of the tokens\n",
    "  response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt='write down a list without spaces of names of cryptocurrency tokens which are mentioned in a positive context in the following text: \\n\\n'+text,\n",
    "  temperature=0.2,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    "    )\n",
    "  shilling_list = response[\"choices\"][0]['text'][2:].split(',')\n",
    "  return shilling_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which takes the list of crypto project and finds the most suitable (by Levenstein distance) ticker in CoinMarketCap database, returns the ticker and market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_and_marketcap(coin):\n",
    "    rat = 0.0\n",
    "    for cmcoin in cmcap_coins:\n",
    "        if 0.8<rat<ratio(coin.lowercap(),cmcoin['name'].lowercap()):\n",
    "            rat = ratio(coin.lowercap(),cmcoin['name'].lowercap())\n",
    "            ticker = cmcoin['symbol']\n",
    "            mcap = cmcoin['market_cap']\n",
    "    return ticker,mcap\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function which monitors the channel and if the new video is uoloaded, then applies functions get_last_video_info(), get_audio_and_text(), get_ticker_and_marketcap() and returns the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_channel(link):\n",
    "    video_date,video_id = get_last_video_info(link)\n",
    "    print(video_date)\n",
    "    report=[[]]\n",
    "    text = get_audio_and_text(video_id)\n",
    "    shilling_list = get_coins_from_text(text)\n",
    "    for shitcoin in shilling_list:\n",
    "        ticker,mcap = get_ticker_and_marketcap(shitcoin)\n",
    "        report.append([ticker,mcap])\n",
    "    while True:\n",
    "        try:\n",
    "            video_date_new,video_id_new = get_last_video_info(link)\n",
    "            print(video_date_new)\n",
    "            if video_id_new!=video_id:\n",
    "                report=[[]]\n",
    "                text = get_audio_and_text(video_id_new)\n",
    "                shilling_list = get_coins_from_text(text)\n",
    "                for shitcoin in shilling_list:\n",
    "                    ticker,mcap = get_ticker_and_marketcap(shitcoin)\n",
    "                    report.append([ticker,mcap])\n",
    "        except Exception as e: print(e)\n",
    "        return report\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "butoshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60c5382a3e0b9582e1a742206d19f370dd95304c059874d908f19a19044a06d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
